{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN4OJTJs6OGxhRqde+alygY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"quPbnK2UlvN8","executionInfo":{"status":"ok","timestamp":1696761087973,"user_tz":-120,"elapsed":2003,"user":{"displayName":"Tesi Polito","userId":"06322488515562524575"}},"outputId":"74aa566c-d962-48f4-c879-e933c72725e9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!pip install rouge\n","import json\n","import nltk\n","from nltk.stem import PorterStemmer\n","from nltk.tokenize import word_tokenize\n","from rouge import Rouge\n","import nltk.translate\n","from nltk.translate import meteor_score\n","import progressbar\n","import numpy as np\n","nltk.download('punkt')\n","nltk.download('wordnet')"],"metadata":{"id":"91PY-UeElx9X","executionInfo":{"status":"ok","timestamp":1696761106847,"user_tz":-120,"elapsed":18140,"user":{"displayName":"Tesi Polito","userId":"06322488515562524575"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"148c1a80-862f-497a-ef02-f161ac9d9493"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: rouge in /usr/local/lib/python3.10/dist-packages (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["path_gold = '/content/drive/MyDrive/Thesis/Models_whole_data/case_explanation/metrics and results/gold_explanations_ranked.json'\n","path_occ = '/content/drive/MyDrive/Thesis/Models_whole_data/case_explanation/LSGBERT_bigru/occlusion_scores/occ_exp_full_0.4.json'\n","g_json = open(path_gold, \"r\")\n","gold_exp = json.load(g_json)\n","o_json = open(path_occ, \"r\")\n","occ_exp = json.load(o_json)"],"metadata":{"id":"OxaltJuccuAN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["files = list(occ_exp.keys())"],"metadata":{"id":"AgpLA5S0my45"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(files)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cuz5XN7gg2tb","executionInfo":{"status":"ok","timestamp":1696756683111,"user_tz":-120,"elapsed":26,"user":{"displayName":"Tesi Polito","userId":"06322488515562524575"}},"outputId":"aab4b8b3-6e58-4149-fc31-55dbab13beaa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['1962_213.txt', '1962_47.txt', '1951_35.txt', '1953_74.txt', '1960_100.txt', '1960_72.txt', '1963_37.txt', '1951_33.txt', '1952_42.txt', '1953_26.txt', '1962_128.txt', '1959_5.txt', '1951_30.txt', '1962_118.txt', '1952_60.txt', '1951_40.txt', '1959_26.txt', '1961_363.txt', '1954_144.txt', '1951_64.txt', '1960_12.txt', '1954_0.txt', '1961_344.txt', '1959_76.txt', '1960_327.txt', '1951_36.txt', '1954_114.txt', '1959_66.txt', '1960_10.txt', '1962_105.txt', '1961_365.txt', '1962_207.txt', '1962_339.txt', '1960_103.txt', '1961_400.txt', '1952_75.txt', '1953_57.txt', '1961_417.txt', '1959_189.txt', '1959_134.txt', '1960_87.txt', '1962_384.txt', '1954_13.txt', '1960_44.txt', '1951_80.txt', '1951_10.txt', '1954_158.txt', '1953_14.txt', '1962_113.txt', '1960_265.txt', '2013_35.txt', '2003_794.txt', '1999_1001.txt', '2013_30.txt', '2013_95.txt', '2013_57.txt']\n"]}]},{"cell_type":"code","source":["def get_BLEU_score(ref_text, machine_text):\n","    tok_ref_text = word_tokenize(ref_text)\n","    tok_machine_text = word_tokenize(machine_text)\n","    score = nltk.translate.bleu_score.sentence_bleu([tok_ref_text], tok_machine_text, weights = (0.5,0.5))\n","    return score"],"metadata":{"id":"BnEJsJ-6jqk3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_METEOR_score(ref_text, machine_text):\n","    tok_ref_text = word_tokenize(ref_text)\n","    tok_machine_text = word_tokenize(machine_text)\n","    score = nltk.translate.meteor_score.meteor_score([tok_ref_text], tok_machine_text)\n","    return score"],"metadata":{"id":"bmz3FKRijrG1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def jaccard_similarity(query, document):\n","    query = word_tokenize(query)\n","    document = word_tokenize(document)\n","    intersection = set(query).intersection(set(document))\n","    union = set(query).union(set(document))\n","    if(len(union)==0):\n","        return 0\n","    return len(intersection)/len(union)"],"metadata":{"id":"MRXTzTKQj7RC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def overlap_coefficient_min(query, document):\n","    query = word_tokenize(query)\n","    document = word_tokenize(document)\n","    intersection = set(query).intersection(set(document))\n","    den = min(len(set(query)),len(set(document)))\n","    if(den==0):\n","        return 0\n","    return len(intersection)/den"],"metadata":{"id":"BK6LlFHOj76n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def overlap_coefficient_max(query, document):\n","    query = word_tokenize(query)\n","    document = word_tokenize(document)\n","    intersection = set(query).intersection(set(document))\n","    den = max(len(set(query)),len(set(document)))\n","    if(den==0):\n","        return 0\n","    return len(intersection)/den"],"metadata":{"id":"wVyd3nPNj9_Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def occ_result_maker(file_to_write, Rank_initial, Rank_final, occ_exp, gold_exp):\n","    rouge1 = []\n","    rouge2 = []\n","    rougel = []\n","    jaccard = []\n","    bleu = []\n","    meteor = []\n","    overlap_min = []\n","    overlap_max = []\n","\n","    for u in range(5):\n","        user = \"User \" + str(u+1)\n","        r1 = []\n","        r2 = []\n","        rl = []\n","        jacc = []\n","        bl = []\n","        met = []\n","        omin = []\n","        omax = []\n","\n","        for i in progressbar.progressbar(range(len(files))):\n","            f = files[i]\n","            ref_text = \"\"\n","            for rank in range(Rank_initial, Rank_final+1, 1):\n","                if(gold_exp[f][user][\"exp\"][\"Rank\" + str(rank)]!=\"\"): # check if user x has sentence in rank y\n","                    ref_text += gold_exp[f][user][\"exp\"][\"Rank\" + str(rank)] + \" \" # if yes save the text of all the renk considered in ref_text\n","\n","            machine_text = occ_exp[f]\n","            machine_text = machine_text.lower()\n","            ref_text = ref_text.lower()\n","\n","            if(ref_text == \"\"):\n","                continue\n","            rouge = Rouge()\n","            score = rouge.get_scores(machine_text, ref_text)\n","            r1.append(score[0]['rouge-1']['f'])\n","            r2.append(score[0]['rouge-2']['f'])\n","            rl.append(score[0]['rouge-l']['f'])\n","            jacc.append(jaccard_similarity(ref_text, machine_text))\n","            omin.append(overlap_coefficient_min(ref_text, machine_text))\n","            omax.append(overlap_coefficient_max(ref_text, machine_text))\n","            bl.append(get_BLEU_score(ref_text, machine_text))\n","            met.append(get_METEOR_score(ref_text, machine_text))\n","\n","        rouge1.append(np.mean(r1))\n","        rouge2.append(np.mean(r2))\n","        rougel.append(np.mean(rl))\n","        jaccard.append(np.mean(jacc))\n","        overlap_min.append(np.mean(omin))\n","        overlap_max.append(np.mean(omax))\n","        bleu.append(np.mean(bl))\n","        meteor.append(np.mean(met))\n","\n","    file_to_write.write(\"ROUGE-1 : {:}\".format(rouge1) + \"\\n\\n\")\n","    file_to_write.write(\"ROUGE-2 : {:}\".format(rouge2) + \"\\n\\n\")\n","    file_to_write.write(\"ROUGE-L : {:}\".format(rougel)+ \"\\n\\n\")\n","    file_to_write.write(\"Jaccard : {:}\".format(jaccard)+ \"\\n\\n\")\n","    file_to_write.write(\"Overmin : {:}\".format(overlap_min)+ \"\\n\\n\")\n","    file_to_write.write(\"Overmax : {:}\".format(overlap_max)+ \"\\n\\n\")\n","    file_to_write.write(\"BLEU    : {:}\".format(bleu)+ \"\\n\\n\")\n","    file_to_write.write(\"METEOR  : {:}\".format(meteor)+ \"\\n\\n\")"],"metadata":{"id":"Nq98LQ9Oe0lf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["experiments = [(1,10), (1,1), (2,2), (3,3), (4,4), (5,5), (6,6), (7,7), (8,8), (9,9), (10,10), (1,5), (5,10)]\n","for exp in experiments:\n","    print(exp)\n","    f = open(\"/content/drive/MyDrive/Thesis/Models_whole_data/case_explanation/metrics and results/result_files/Rank_\" + str(exp[0]) + \"_to_\" + str(exp[1]) + \".txt\", \"w\")\n","    occ_result_maker(f, exp[0], exp[1], occ_exp, gold_exp)"],"metadata":{"id":"2-DHZFIFdz21","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696758146702,"user_tz":-120,"elapsed":1463613,"user":{"displayName":"Tesi Polito","userId":"06322488515562524575"}},"outputId":"4e48efa7-d802-43e0-8457-846734bdae86"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\r  0% (0 of 56) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--"]},{"output_type":"stream","name":"stdout","text":["(1, 10)\n"]},{"output_type":"stream","name":"stderr","text":["100% (56 of 56) |########################| Elapsed Time: 0:01:32 Time:  0:01:32\n","100% (56 of 56) |########################| Elapsed Time: 0:00:52 Time:  0:00:52\n","100% (56 of 56) |########################| Elapsed Time: 0:01:54 Time:  0:01:54\n","100% (56 of 56) |########################| Elapsed Time: 0:02:12 Time:  0:02:12\n","100% (56 of 56) |########################| Elapsed Time: 0:01:08 Time:  0:01:08\n","  0% (0 of 56) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--"]},{"output_type":"stream","name":"stdout","text":["(1, 1)\n"]},{"output_type":"stream","name":"stderr","text":["100% (56 of 56) |########################| Elapsed Time: 0:00:12 Time:  0:00:12\n","100% (56 of 56) |########################| Elapsed Time: 0:00:14 Time:  0:00:14\n","100% (56 of 56) |########################| Elapsed Time: 0:00:47 Time:  0:00:47\n","100% (56 of 56) |########################| Elapsed Time: 0:00:10 Time:  0:00:10\n","100% (56 of 56) |########################| Elapsed Time: 0:00:10 Time:  0:00:10\n","  0% (0 of 56) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--"]},{"output_type":"stream","name":"stdout","text":["(2, 2)\n"]},{"output_type":"stream","name":"stderr","text":["100% (56 of 56) |########################| Elapsed Time: 0:00:22 Time:  0:00:22\n","100% (56 of 56) |########################| Elapsed Time: 0:00:18 Time:  0:00:18\n","100% (56 of 56) |########################| Elapsed Time: 0:00:48 Time:  0:00:48\n","100% (56 of 56) |########################| Elapsed Time: 0:00:27 Time:  0:00:27\n"," 44% (25 of 56) |##########              | Elapsed Time: 0:00:04 ETA:   0:00:05/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 2-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","100% (56 of 56) |########################| Elapsed Time: 0:00:09 Time:  0:00:09\n","  0% (0 of 56) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--"]},{"output_type":"stream","name":"stdout","text":["(3, 3)\n"]},{"output_type":"stream","name":"stderr","text":["100% (56 of 56) |########################| Elapsed Time: 0:00:25 Time:  0:00:25\n","100% (56 of 56) |########################| Elapsed Time: 0:00:18 Time:  0:00:18\n","100% (56 of 56) |########################| Elapsed Time: 0:00:22 Time:  0:00:22\n","100% (56 of 56) |########################| Elapsed Time: 0:00:53 Time:  0:00:53\n","100% (56 of 56) |########################| Elapsed Time: 0:00:16 Time:  0:00:16\n","  0% (0 of 56) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--"]},{"output_type":"stream","name":"stdout","text":["(4, 4)\n"]},{"output_type":"stream","name":"stderr","text":["100% (56 of 56) |########################| Elapsed Time: 0:00:24 Time:  0:00:24\n","100% (56 of 56) |########################| Elapsed Time: 0:00:08 Time:  0:00:08\n","100% (56 of 56) |########################| Elapsed Time: 0:00:06 Time:  0:00:06\n","100% (56 of 56) |########################| Elapsed Time: 0:00:36 Time:  0:00:36\n","100% (56 of 56) |########################| Elapsed Time: 0:00:15 Time:  0:00:15\n","  0% (0 of 56) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--"]},{"output_type":"stream","name":"stdout","text":["(5, 5)\n"]},{"output_type":"stream","name":"stderr","text":["100% (56 of 56) |########################| Elapsed Time: 0:00:06 Time:  0:00:06\n","100% (56 of 56) |########################| Elapsed Time: 0:00:01 Time:  0:00:01\n","100% (56 of 56) |########################| Elapsed Time: 0:00:00 Time:  0:00:00\n","100% (56 of 56) |########################| Elapsed Time: 0:00:13 Time:  0:00:13\n","100% (56 of 56) |########################| Elapsed Time: 0:00:13 Time:  0:00:13\n","  0% (0 of 56) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--"]},{"output_type":"stream","name":"stdout","text":["(6, 6)\n"]},{"output_type":"stream","name":"stderr","text":["100% (56 of 56) |########################| Elapsed Time: 0:00:00 Time:  0:00:00\n","100% (56 of 56) |########################| Elapsed Time: 0:00:00 Time:  0:00:00\n","100% (56 of 56) |########################| Elapsed Time: 0:00:00 Time:  0:00:00\n","/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n","  return _methods._mean(a, axis=axis, dtype=dtype,\n","/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n","  ret = ret.dtype.type(ret / rcount)\n","100% (56 of 56) |########################| Elapsed Time: 0:00:02 Time:  0:00:02\n","100% (56 of 56) |########################| Elapsed Time: 0:00:11 Time:  0:00:11\n","  0% (0 of 56) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--"]},{"output_type":"stream","name":"stdout","text":["(7, 7)\n"]},{"output_type":"stream","name":"stderr","text":["100% (56 of 56) |########################| Elapsed Time: 0:00:01 Time:  0:00:01\n","100% (56 of 56) |########################| Elapsed Time: 0:00:00 Time:  0:00:00\n","100% (56 of 56) |########################| Elapsed Time: 0:00:00 Time:  0:00:00\n","100% (56 of 56) |########################| Elapsed Time: 0:00:00 Time:  0:00:00\n","100% (56 of 56) |########################| Elapsed Time: 0:00:05 Time:  0:00:05\n","100% (56 of 56) |########################| Elapsed Time: 0:00:00 Time:  0:00:00\n","100% (56 of 56) |########################| Elapsed Time: 0:00:00 Time:  0:00:00\n","100% (56 of 56) |########################| Elapsed Time: 0:00:00 Time:  0:00:00\n","100% (56 of 56) |########################| Elapsed Time: 0:00:00 Time:  0:00:00\n","  0% (0 of 56) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--"]},{"output_type":"stream","name":"stdout","text":["(8, 8)\n"]},{"output_type":"stream","name":"stderr","text":["100% (56 of 56) |########################| Elapsed Time: 0:00:06 Time:  0:00:06\n","100% (56 of 56) |########################| Elapsed Time: 0:00:00 Time:  0:00:00\n","100% (56 of 56) |########################| Elapsed Time: 0:00:00 Time:  0:00:00\n","100% (56 of 56) |########################| Elapsed Time: 0:00:00 Time:  0:00:00\n","100% (56 of 56) |########################| Elapsed Time: 0:00:00 Time:  0:00:00\n","  0% (0 of 56) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--"]},{"output_type":"stream","name":"stdout","text":["(9, 9)\n"]},{"output_type":"stream","name":"stderr","text":["100% (56 of 56) |########################| Elapsed Time: 0:00:01 Time:  0:00:01\n","100% (56 of 56) |########################| Elapsed Time: 0:00:00 Time:  0:00:00\n","100% (56 of 56) |########################| Elapsed Time: 0:00:00 Time:  0:00:00\n","100% (56 of 56) |########################| Elapsed Time: 0:00:00 Time:  0:00:00\n","  0% (0 of 56) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--"]},{"output_type":"stream","name":"stdout","text":["(10, 10)\n"]},{"output_type":"stream","name":"stderr","text":["100% (56 of 56) |########################| Elapsed Time: 0:00:00 Time:  0:00:00\n","100% (56 of 56) |########################| Elapsed Time: 0:00:00 Time:  0:00:00\n","  0% (0 of 56) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--"]},{"output_type":"stream","name":"stdout","text":["(1, 5)\n"]},{"output_type":"stream","name":"stderr","text":["100% (56 of 56) |########################| Elapsed Time: 0:01:17 Time:  0:01:17\n","100% (56 of 56) |########################| Elapsed Time: 0:00:55 Time:  0:00:55\n","100% (56 of 56) |########################| Elapsed Time: 0:01:56 Time:  0:01:56\n","100% (56 of 56) |########################| Elapsed Time: 0:02:09 Time:  0:02:09\n","100% (56 of 56) |########################| Elapsed Time: 0:00:53 Time:  0:00:53\n","  0% (0 of 56) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--"]},{"output_type":"stream","name":"stdout","text":["(5, 10)\n"]},{"output_type":"stream","name":"stderr","text":["100% (56 of 56) |########################| Elapsed Time: 0:00:07 Time:  0:00:07\n","100% (56 of 56) |########################| Elapsed Time: 0:00:02 Time:  0:00:02\n","100% (56 of 56) |########################| Elapsed Time: 0:00:00 Time:  0:00:00\n","100% (56 of 56) |########################| Elapsed Time: 0:00:16 Time:  0:00:16\n","100% (56 of 56) |########################| Elapsed Time: 0:00:27 Time:  0:00:27\n"]}]},{"cell_type":"code","source":["# COMPUTE MEAN TOKENS IN ANNOTED DATASET"],"metadata":{"id":"GsJYvZ35yLcP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","# load the entire test set\n","dataset = pd.read_csv('/content/drive/MyDrive/Thesis/train_data/ILDC_multi.csv')\n","test = dataset.loc[dataset['split'] == 'test']"],"metadata":{"id":"STSlae1GvnZC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# filtered test set\n","test = test.reset_index(drop=True) # reset index of the test set\n","filter = test['name'].isin(files) # create a filter that includes only the docs contained in ILDCexpert\n","df = test[filter] # dataframe of the documents in ILDCexpert -> lenght = 56"],"metadata":{"id":"NQUpwZbDyiZq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tot=0\n","for i in range(len(df)):\n","  text = df.iloc[i]['text']\n","  tok_text = word_tokenize(text)\n","  tot += len(tok_text)\n","\n","print(f'The mean tokens of the annotated docs is: {tot/len(df)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R5u8_Cawyns8","executionInfo":{"status":"ok","timestamp":1696760487972,"user_tz":-120,"elapsed":2146,"user":{"displayName":"Tesi Polito","userId":"06322488515562524575"}},"outputId":"c1e5c857-b524-4f49-995e-9cb16b1ecece"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The mean tokens of the annotated docs is: 3162.214285714286\n"]}]},{"cell_type":"code","source":["tot = 0\n","for i in range(len(files)):\n","  f = files[i]\n","  machine_text = occ_exp[f]\n","  tok_machine_text = word_tokenize(machine_text)\n","  tot += len(tok_machine_text)\n","\n","print(f'The mean tokens of the machine docs is: {tot/56}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RLyrUNiQx5mR","executionInfo":{"status":"ok","timestamp":1696760613683,"user_tz":-120,"elapsed":342,"user":{"displayName":"Tesi Polito","userId":"06322488515562524575"}},"outputId":"fb80f2b5-fe9b-45b4-f1ff-9829a758c06a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The mean tokens of the machine docs is: 717.75\n"]}]},{"cell_type":"code","source":["path_authors = '/content/drive/MyDrive/Thesis/Models_whole_data/case_explanation/metrics and results/occ_explanations.json'\n","a_json = open(path_authors, \"r\")\n","occ_authors = json.load(a_json)"],"metadata":{"id":"PHKkwjGdzmo9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tot = 0\n","for i in range(len(files)):\n","  f = files[i]\n","  machine_text = occ_authors[f]\n","  tok_machine_text = word_tokenize(machine_text)\n","  tot += len(tok_machine_text)\n","\n","print(f'The mean tokens of the machine docs of the AUTHORS is: {tot/56}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1oMKRW3K1aLB","executionInfo":{"status":"ok","timestamp":1696761152771,"user_tz":-120,"elapsed":353,"user":{"displayName":"Tesi Polito","userId":"06322488515562524575"}},"outputId":"ae9835f9-8cb7-466a-8339-32a2387e9574"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The mean tokens of the machine docs of the AUTHORS is: 730.4107142857143\n"]}]}]}