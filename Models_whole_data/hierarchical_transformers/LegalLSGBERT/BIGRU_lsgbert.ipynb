{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP3wrKkU2CMY9X0LRKk0h8R"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nBeZYdAu_2Cb","executionInfo":{"status":"ok","timestamp":1688548109661,"user_tz":-120,"elapsed":1672,"user":{"displayName":"Tesi Polito","userId":"06322488515562524575"}},"outputId":"c50edd80-8491-4f93-9d89-ea1dcea1bf20"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from keras import Sequential\n","from keras.utils import Sequence\n","from keras.layers import LSTM, Dense, Masking, GRU\n","import numpy as np\n","import keras\n","from keras.utils import np_utils\n","from keras import optimizers\n","from keras.models import Sequential, Model\n","from keras.layers import Embedding, Dense, Input, concatenate, Layer, Lambda, Dropout, Activation\n","import datetime\n","from datetime import datetime\n","from keras.callbacks import ModelCheckpoint, EarlyStopping, Callback, TensorBoard\n","from keras.callbacks import ReduceLROnPlateau\n","from keras.models import load_model\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","import numpy as np\n","from numpy import load\n","import pandas as pd\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import confusion_matrix\n","\n","\n","np.random.seed(1337)# setting the random seed value"],"metadata":{"id":"4nHJ0kHs__gS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = pd.read_csv('/content/drive/MyDrive/Thesis/train_data/ILDC_multi.csv') # loading dataset"],"metadata":{"id":"eEZAuiBMAAi1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# path to transformer generated chunk embeddings\n","path_transformer_chunk_embeddings_train = '/content/drive/MyDrive/Thesis/Models_whole_data/transformers_sentence_level/LSGBERT_multi/LSGBERT_npy_files_cls_multi/LSGBERT_cls_train.npy'\n","path_transformer_chunk_embeddings_dev = '/content/drive/MyDrive/Thesis/Models_whole_data/transformers_sentence_level/LSGBERT_multi/LSGBERT_npy_files_cls_multi/LSGBERT_cls_dev.npy'\n","path_transformer_chunk_embeddings_test = '/content/drive/MyDrive/Thesis/Models_whole_data/transformers_sentence_level/LSGBERT_multi/LSGBERT_npy_files_cls_multi/LSGBERT_cls_test.npy'"],"metadata":{"id":"6qL7RejoAZUo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# loading the chunk embeddings\n","x_train0 = load(path_transformer_chunk_embeddings_train, allow_pickle = True)\n","x_dev0 = load(path_transformer_chunk_embeddings_dev, allow_pickle= True)\n","x_test0 = load(path_transformer_chunk_embeddings_test, allow_pickle= True)"],"metadata":{"id":"2-_9HfjWCZ_y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# loading the corresponding label for each case in dataset\n","dev = dataset.loc[dataset['split'] == 'dev']\n","train = dataset.loc[dataset['split'] == 'train']\n","test = dataset.loc[dataset['split'] == 'test']\n","\n","y_train0 = []\n","for i in range(train.shape[0]):\n","    y_train0.append(train.loc[i,'label'])\n","\n","y_dev0 = []\n","for i in range(dev.shape[0]):\n","    y_dev0.append(dev.loc[i+32305,'label'])\n","\n","y_test0 = []\n","for i in range(test.shape[0]):\n","    y_test0.append(test.loc[i+33299,'label'])"],"metadata":{"id":"OnFEN7GMH0RM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras import layers\n","# Input layer to convert into required tensor shape\n","text_input = Input(shape=(None,768,), dtype='float32', name='text')\n","# Masking layer to mask the padded values\n","l_mask = layers.Masking(mask_value=-99.)(text_input)\n","# After masking we encoded the vector using 2 bidirectional GRU's\n","encoded_text = layers.Bidirectional(GRU(100,return_sequences=True))(l_mask)\n","encoded_text1 = layers.Bidirectional(GRU(100,))(encoded_text)\n","# Added a dense layer after encoding\n","out_dense = layers.Dense(30, activation='relu')(encoded_text1)\n","# And we add a sigmoid classifier on top\n","out = layers.Dense(1, activation='sigmoid')(out_dense)\n","# At model instantiation, we specify the input and the output:\n","model = Model(text_input, out)\n","model.compile(optimizer='Adam',\n","              loss='binary_crossentropy',\n","              metrics=['acc'])\n","model.summary()"],"metadata":{"id":"z6LM4pdNJmBi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1688548139553,"user_tz":-120,"elapsed":5083,"user":{"displayName":"Tesi Polito","userId":"06322488515562524575"}},"outputId":"728e1047-0a76-4f6d-9057-4b326a2fa1a2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," text (InputLayer)           [(None, None, 768)]       0         \n","                                                                 \n"," masking (Masking)           (None, None, 768)         0         \n","                                                                 \n"," bidirectional (Bidirectiona  (None, None, 200)        522000    \n"," l)                                                              \n","                                                                 \n"," bidirectional_1 (Bidirectio  (None, 200)              181200    \n"," nal)                                                            \n","                                                                 \n"," dense (Dense)               (None, 30)                6030      \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 31        \n","                                                                 \n","=================================================================\n","Total params: 709,261\n","Trainable params: 709,261\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["num_sequences = len(x_train0)\n","batch_size = 32\n","batches_per_epoch =  int(num_sequences/batch_size)\n","num_features= 768\n","def train_generator(): # function to generate batches of corresponding batch size\n","    x_list= x_train0\n","    y_list =  y_train0\n","    # Generate batches\n","    while True:\n","        for b in range(batches_per_epoch):\n","            longest_index = (b + 1) * batch_size - 1\n","            timesteps = len(max(x_train0[:(b + 1) * batch_size][-batch_size:], key=len))\n","            x_train = np.full((batch_size, timesteps, num_features), -99.)\n","            y_train = np.zeros((batch_size,  1))\n","            # padding the vectors with respect to the maximum sequence of each batch and not the whole training data\n","            for i in range(batch_size):\n","                li = b * batch_size + i\n","                x_train[i, 0:len(x_list[li]), :] = x_list[li]\n","                y_train[i] = y_list[li]\n","            yield x_train, y_train"],"metadata":{"id":"BoK5NCQP_cO-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_sequences_val = len(x_dev0)\n","batch_size_val = 32\n","batches_per_epoch_val = int(num_sequences_val/batch_size_val)\n","num_features= 768\n","def val_generator():# Similar function to generate validation batches\n","    x_list= x_dev0\n","    y_list =  y_dev0\n","    # Generate batches\n","    while True:\n","        for b in range(batches_per_epoch_val):\n","            longest_index = (b + 1) * batch_size_val - 1\n","            timesteps = len(max(x_dev0[:(b + 1) * batch_size_val][-batch_size_val:], key=len))\n","            x_train = np.full((batch_size_val, timesteps, num_features), 0)\n","            y_train = np.zeros((batch_size_val,  1))\n","            # padding the vectors with respect to the maximum sequence of each batch and not the whole validation data\n","            for i in range(batch_size_val):\n","                li = b * batch_size_val + i\n","                x_train[i, 0:len(x_list[li]), :] = x_list[li]\n","                y_train[i] = y_list[li]\n","            yield x_train, y_train"],"metadata":{"id":"xO_tFYok_fIx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Setting the callback and training the model\n","call_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.95, patience=2, verbose=2,\n","                                mode='auto', min_delta=0.01, cooldown=0, min_lr=0)\n","\n","model.fit(train_generator(), steps_per_epoch=batches_per_epoch, epochs=3,\n","                    validation_data=val_generator(), validation_steps=batches_per_epoch_val, callbacks =[call_reduce] )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JZ3NMoG5_kQx","executionInfo":{"status":"ok","timestamp":1688548235565,"user_tz":-120,"elapsed":96029,"user":{"displayName":"Tesi Polito","userId":"06322488515562524575"}},"outputId":"9ffe364e-bd76-4a61-b341-e526e2e0eaa6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","1009/1009 [==============================] - 49s 28ms/step - loss: 0.3010 - acc: 0.8790 - val_loss: 0.6405 - val_acc: 0.6905 - lr: 0.0010\n","Epoch 2/3\n","1009/1009 [==============================] - 22s 22ms/step - loss: 0.2831 - acc: 0.8861 - val_loss: 0.6350 - val_acc: 0.6956 - lr: 0.0010\n","Epoch 3/3\n","1009/1009 [==============================] - ETA: 0s - loss: 0.2709 - acc: 0.8914\n","Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n","1009/1009 [==============================] - 23s 23ms/step - loss: 0.2709 - acc: 0.8914 - val_loss: 0.6361 - val_acc: 0.6956 - lr: 0.0010\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f91ad1027a0>"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["num_sequences_test = len(x_test0)\n","batch_size_test = 32\n","batches_per_epoch_test = int(num_sequences_test/batch_size_test) + 1\n","num_features= 768\n","def test_generator(): # function to generate batches of corresponding batch size\n","    x_list= x_test0\n","    y_list =  y_test0\n","    # Generate batches\n","    while True:\n","        for b in range(batches_per_epoch_test):\n","            if(b == batches_per_epoch_test-1): # An extra if else statement just to manage the last batch as it's size might not be equal to batch size\n","              longest_index = num_sequences_test - 1\n","              timesteps = len(max(x_test0[:longest_index + 1][-batch_size_test:], key=len))\n","              x_train = np.full((longest_index - b*batch_size_test, timesteps, num_features), -99.)\n","              y_train = np.zeros((longest_index - b*batch_size_test,  1))\n","              for i in range(longest_index - b*batch_size_test):\n","                  li = b * batch_size_test + i\n","                  x_train[i, 0:len(x_list[li]), :] = x_list[li]\n","                  y_train[i] = y_list[li]\n","            else:\n","                longest_index = (b + 1) * batch_size_test - 1\n","                timesteps = len(max(x_test0[:(b + 1) * batch_size_test][-batch_size_test:], key=len))\n","                x_train = np.full((batch_size_test, timesteps, num_features), -99.)\n","                y_train = np.zeros((batch_size_test,  1))\n","                # padding the vectors with respect to the maximum sequence of each batch and not the whole test data\n","                for i in range(batch_size_test):\n","                    li = b * batch_size_test + i\n","                    x_train[i, 0:len(x_list[li]), :] = x_list[li]\n","                    y_train[i] = y_list[li]\n","            yield x_train, y_train"],"metadata":{"id":"TW_0Rk3u-inx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# evaluating on the test data\n","model.evaluate_generator(test_generator(), steps= batches_per_epoch_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_gfgQPwD-0Jy","executionInfo":{"status":"ok","timestamp":1688548242158,"user_tz":-120,"elapsed":6611,"user":{"displayName":"Tesi Polito","userId":"06322488515562524575"}},"outputId":"18669a54-5bd9-4662-96d3-4ddbb657667f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-12-8e91bbf97f2e>:2: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n","  model.evaluate_generator(test_generator(), steps= batches_per_epoch_test)\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.4462881088256836, 0.8205804824829102]"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["# defining a function which calculates various metrics such as micro and macro precision, accuracy and f1\n","def metrics_calculator(preds, test_labels):\n","    cm = confusion_matrix(test_labels, preds)\n","    TP = []\n","    FP = []\n","    FN = []\n","    for i in range(0,2):\n","        summ = 0\n","        for j in range(0,2):\n","            if(i!=j):\n","                summ=summ+cm[i][j]\n","\n","        FN.append(summ)\n","    for i in range(0,2):\n","        summ = 0\n","        for j in range(0,2):\n","            if(i!=j):\n","                summ=summ+cm[j][i]\n","\n","        FP.append(summ)\n","    for i in range(0,2):\n","        TP.append(cm[i][i])\n","    precision = []\n","    recall = []\n","    for i in range(0,2):\n","        precision.append(TP[i]/(TP[i] + FP[i]))\n","        recall.append(TP[i]/(TP[i] + FN[i]))\n","\n","    macro_precision = sum(precision)/2\n","    macro_recall = sum(recall)/2\n","    micro_precision = sum(TP)/(sum(TP) + sum(FP))\n","    micro_recall = sum(TP)/(sum(TP) + sum(FN))\n","    micro_f1 = (2*micro_precision*micro_recall)/(micro_precision + micro_recall)\n","    macro_f1 = (2*macro_precision*macro_recall)/(macro_precision + macro_recall)\n","    return macro_precision, macro_recall, macro_f1, micro_precision, micro_recall, micro_f1"],"metadata":{"id":"X55xIhE2BgVi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.evaluate(val_generator(), steps= batches_per_epoch_val)"],"metadata":{"id":"1bcSI0KHGPgt","executionInfo":{"status":"ok","timestamp":1688548243034,"user_tz":-120,"elapsed":881,"user":{"displayName":"Tesi Polito","userId":"06322488515562524575"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e56f5ae1-2015-4fa3-b73e-1cd898063b87"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 0s 12ms/step - loss: 0.6361 - acc: 0.6956\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.6360851526260376, 0.6955645084381104]"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["# getting the predicted labels on the dev data\n","preds = model.predict(val_generator(), steps= batches_per_epoch_val)\n","y_pred_dev = preds > 0.5\n","\n","# Calculating all metrics on dev data predicted label\n","print(metrics_calculator(y_pred_dev, y_dev0[:-2]))"],"metadata":{"executionInfo":{"status":"ok","timestamp":1688548247902,"user_tz":-120,"elapsed":4871,"user":{"displayName":"Tesi Polito","userId":"06322488515562524575"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1e265d0e-54db-4f9c-e10f-3858cdcea6a8","id":"pb0wH-jBGU4n"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 5s 11ms/step\n","(0.7796688988095238, 0.6955645161290323, 0.7352192742514433, 0.6955645161290323, 0.6955645161290323, 0.6955645161290323)\n"]}]},{"cell_type":"code","source":["# getting the predicted labels on the test data\n","preds = model.predict_generator(test_generator(), steps= batches_per_epoch_test)\n","y_pred = preds > 0.5\n","\n","# Calculating all metrics on test data predicted label\n","print(metrics_calculator(y_pred, y_test0[:-1]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1688548253616,"user_tz":-120,"elapsed":5729,"user":{"displayName":"Tesi Polito","userId":"06322488515562524575"}},"outputId":"e9aecbd9-6fa3-4175-84da-50de3c74e4d8","id":"s2sv2n-JGU4o"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-16-129cc16c0af6>:2: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  preds = model.predict_generator(test_generator(), steps= batches_per_epoch_test)\n"]},{"output_type":"stream","name":"stdout","text":["(0.8206491749973455, 0.8206089930467928, 0.8206290835301937, 0.820580474934037, 0.820580474934037, 0.8205804749340369)\n"]}]}]}